{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import yaml\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "import began\n",
    "from began.logging import setup_vae_run_logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Working with GPU: True\n",
      "INFO:root:\n",
      "Network parameters:\n",
      "    Size of latent dimension: 256\n",
      "    Batch size: 8\n",
      "    Epochs: 400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize random seed in numpy\n",
    "np.random.seed(123454321)\n",
    "# initialize random seed in tensorflow\n",
    "tf.random.set_seed(123454321)\n",
    "\n",
    "plot_dir = Path(\"../reports/figures\").absolute()\n",
    "\n",
    "cfg = {}\n",
    "\n",
    "with open(\"../configs/training/vae_train_default.yaml\") as f:\n",
    "    cfg.update(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "with open(\"../configs/models/vae_default.yaml\") as f:\n",
    "    cfg.update(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "logging.info(\"\"\"Working with GPU: {:s}\"\"\".format(str(tf.test.is_gpu_available())))\n",
    "\n",
    "logging.info(\"\"\"\n",
    "Network parameters:\n",
    "    Size of latent dimension: {:d}\n",
    "    Batch size: {:d}\n",
    "    Epochs: {:d}\n",
    "\"\"\".format(cfg['lat_dim'], cfg['batch_size'], cfg['epochs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "summary_writer = setup_vae_run_logging(cfg['lat_dim'], cfg['batch_size'], cfg['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bthorne/projects/gan/began/envs-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/bthorne/projects/gan/began/envs-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# Batch and shuffle the data\n",
    "with h5py.File(\"../data/preprocessed/prepared.h5\", 'r') as f:\n",
    "    dset = f[\"cut_maps\"]\n",
    "    train_images = dset[...].astype(np.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_images.shape[0]).map(tf.image.per_image_standardization)\n",
    "test_dataset = dataset.take(100)\n",
    "train_dataset = dataset.skip(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"Builds a convolutional model.\"\"\"\n",
    "    lat_dim = hp.Int('lat_dim', 32, 256)\n",
    "    kernel_size = hp.Choice('kernel_size', values=[3, 5])\n",
    "    return began.CVAE(lat_dim, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "\n",
    "    def run_trial(self, trial, train_ds):\n",
    "        hp = trial.hyperparameters\n",
    "\n",
    "        # Hyperparameters can be added anywhere inside `run_trial`.\n",
    "        # When the first trial is run, they will take on their default values.\n",
    "        # Afterwards, they will be tuned by the `Oracle`.\n",
    "        train_ds = train_ds.batch(hp.Int('batch_size', 8, 32, default=8))\n",
    "        print(type(train_ds))\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log', default=1e-3)\n",
    "        optimizer = tf.keras.optimizers.Adam(beta_1=0.5, learning_rate=lr)\n",
    "        epoch_loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "        @tf.function\n",
    "        def run_train_step(data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = began.vae.compute_loss(model, data)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            epoch_loss_metric.update_state(loss)\n",
    "            return loss\n",
    "\n",
    "        # `self.on_epoch_end` reports results to the `Oracle` and saves the\n",
    "        # current state of the Model. The other hooks called here only log values\n",
    "        # for display but can also be overridden. For use cases where there is no\n",
    "        # natural concept of epoch, you do not have to call any of these hooks. In\n",
    "        # this case you should instead call `self.oracle.update_trial` and\n",
    "        # `self.oracle.save_model` manually.\n",
    "        for epoch in range(3):\n",
    "            print('Epoch: {}'.format(epoch))\n",
    "\n",
    "            self.on_epoch_begin(trial, model, epoch, logs={})\n",
    "            for batch, data in enumerate(train_ds):\n",
    "                self.on_batch_begin(trial, model, batch, logs={})\n",
    "                batch_loss = float(run_train_step(data))\n",
    "                self.on_batch_end(trial, model, batch, logs={'loss': batch_loss})\n",
    "\n",
    "                if batch % 30 == 0:\n",
    "                    loss = epoch_loss_metric.result().numpy()\n",
    "                    print('Batch: {}, Average Loss: {}'.format(batch, loss))\n",
    "\n",
    "            epoch_loss = epoch_loss_metric.result().numpy()\n",
    "            self.on_epoch_end(trial, model, epoch, logs={'loss': epoch_loss})\n",
    "            epoch_loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project results/began_custom_training_hp/oracle.json\n",
      "INFO:tensorflow:Reloading Oracle from existing project results/began_custom_training_hp/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from results/began_custom_training_hp/tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from results/began_custom_training_hp/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = MyTuner(\n",
    "      oracle=kt.oracles.BayesianOptimization(\n",
    "          objective=kt.Objective('loss', 'min'),\n",
    "          max_trials=10),\n",
    "      hypermodel=build_model,\n",
    "      directory='results',\n",
    "      project_name='began_custom_training_hp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lat_dim': 131, 'kernel_size': 5, 'batch_size': 10, 'learning_rate': 0.00019071203207567507}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
